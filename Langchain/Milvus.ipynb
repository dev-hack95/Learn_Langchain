{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d36f5e93-e39d-48b5-bca3-c9aa64937e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_community.llms import CTransformers\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676a87f1-381d-492b-a512-f9f25d5f8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeAnalyser:\n",
    "    def __init__(self, resume) -> None:\n",
    "        \"\"\"\n",
    "        Info:\n",
    "          A Resume vector store function\n",
    "        Args:\n",
    "          resume[Document] --> A pdf document\n",
    "        Returns:\n",
    "          None\n",
    "        \"\"\"\n",
    "        self.resume = resume\n",
    "        self.pdf_loder = PyMuPDFLoader\n",
    "        self.callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "        self.embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.human_template = \"\"\"{question}\"\"\"\n",
    "        self.system_template = \"You are AI assiatant that can analyse the given text and answer the questions according based on given text be more specific about answer: {text}\"\n",
    "        self.collection_name = \"resume_collections\"\n",
    "        self.client_settings = {\n",
    "            \"host\": \"192.168.43.163\",\n",
    "            \"port\": \"19530\"}\n",
    "        self.config = {\n",
    "            'max_new_tokens': 512,\n",
    "            'repetition_penalty': 1.1,\n",
    "            'context_length': 2000,\n",
    "        }\n",
    "        self.model = CTransformers(\n",
    "            model='C:\\\\Users\\\\Saiprasad\\\\.cache\\\\huggingface\\\\hub\\\\models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF\\\\snapshots\\\\3a6fbf4a41a1d52e415a4958cde6856d34b2db93\\\\mistral-7b-instruct-v0.2.Q4_K_M.gguf',\n",
    "            model_type='llama', config=self.config, callback_manager=self.callback_manager)\n",
    "    def Analyse(self, param1, param2):\n",
    "        \"\"\"\n",
    "        Info:\n",
    "          This function used cosine simalarity to analyse the resume\n",
    "        Args:\n",
    "          resume --> Input Resume\n",
    "        Returns:\n",
    "          str --> Returns data based on Cosine-similarity\n",
    "        \"\"\"\n",
    "        resume_data = self.pdf_loder(self.resume)\n",
    "        resumes_data = resume_data.load()\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=2500,\n",
    "            chunk_overlap=10,\n",
    "            length_function=len,\n",
    "            is_separator_regex=False)\n",
    "        data = text_splitter.split_documents(resumes_data)\n",
    "        db = Milvus.from_documents(\n",
    "            data, \n",
    "            self.embedding_model, \n",
    "            connection_args=self.client_settings, \n",
    "            collection_name = self.collection_name)\n",
    "        docs = db.similarity_search(param1, k = 1)\n",
    "        human_prompt = HumanMessagePromptTemplate.from_template(self.human_template)\n",
    "        system_prompt = SystemMessagePromptTemplate.from_template(self.system_template)\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "        prompt = chat_prompt.format_prompt(question=param2, text=docs).to_messages()\n",
    "        return self.model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76263811-eb89-47fb-a8df-26e57853b5c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyser = ResumeAnalyser(\"../data/Saiprasad Toshatwad.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c01f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Assistant: Based on the provided text from Saiprasad Toshatwad's resume, here are the mentioned skill sections:\n",
      "\n",
      "1. SQL (MySQL, PostgreSQL), VectorDB’s\n",
      "2. Python, LangChain (Pandas, Tensorflow, Yellowbrick, Shap, NumPy, Scikit-learn, API, ORM.. etc.)\n",
      "3. Golang, ORM\n",
      "4. MLOps: Linux, Kedro, Docker, Git, DVC, MLflow, AWS, EC2, S3, botot3, AWS lambda, Github Actions\n",
      "5. PowerBI\n",
      "\n",
      "These sections represent the various technical skills and proficiencies that Saiprasad has mentioned in his resume."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\".\\nAssistant: Based on the provided text from Saiprasad Toshatwad's resume, here are the mentioned skill sections:\\n\\n1. SQL (MySQL, PostgreSQL), VectorDB’s\\n2. Python, LangChain (Pandas, Tensorflow, Yellowbrick, Shap, NumPy, Scikit-learn, API, ORM.. etc.)\\n3. Golang, ORM\\n4. MLOps: Linux, Kedro, Docker, Git, DVC, MLflow, AWS, EC2, S3, botot3, AWS lambda, Github Actions\\n5. PowerBI\\n\\nThese sections represent the various technical skills and proficiencies that Saiprasad has mentioned in his resume.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"skills\", \"list down his skill sections on resume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d0dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " as a data scientist?\n",
      "Assistant: Saiprasad Toshatwad has mentioned working as a Data Scientist at Eaton between the years 2023 and 2023."
     ]
    },
    {
     "data": {
      "text/plain": [
       "' as a data scientist?\\nAssistant: Saiprasad Toshatwad has mentioned working as a Data Scientist at Eaton between the years 2023 and 2023.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"Companies\", \"In which companies saiprasad toshatwad worked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec3df32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "AI: Based on the provided text, Saiprasad mentions that he has technical skills in Golang, so we cannot determine exactly how many years of experience he has in this specific programming language from the given information."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'?\\nAI: Based on the provided text, Saiprasad mentions that he has technical skills in Golang, so we cannot determine exactly how many years of experience he has in this specific programming language from the given information.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"Experiance\", \"How many years saiprasad have experiance as golang developer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbcb0a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "Assistant: Based on the provided text, Saiprasad has worked on several projects that involve data analysis and machine learning. However, the text does not explicitly state the number of years he has spent working as a data scientist. Therefore, I cannot provide an accurate answer based on the given text alone."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'?\\nAssistant: Based on the provided text, Saiprasad has worked on several projects that involve data analysis and machine learning. However, the text does not explicitly state the number of years he has spent working as a data scientist. Therefore, I cannot provide an accurate answer based on the given text alone.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"Experiance\", \"How many years saiprasad have experiance as data scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e632006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Based on the given text, Saiprasad has worked on several projects. However, there is no explicit mention of the number of years he has spent on each project or the total number of years he has spent working. Therefore, it's impossible to provide a definitive answer with the information provided in the text."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nAssistant: Based on the given text, Saiprasad has worked on several projects. However, there is no explicit mention of the number of years he has spent on each project or the total number of years he has spent working. Therefore, it's impossible to provide a definitive answer with the information provided in the text.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"Experiance\", \"How many years saiprasad have experiance in total?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7295151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and work experience mentioned in the text.\n",
      "Assistant: I. Projects:\n",
      "1. TextFlow – Personal Project\n",
      "   - Advanced video-to-text summarization with chat and context data project using RabbitMQ, Docker, MongoDB, SQL, and 3-tier architecture.\n",
      "\n",
      "II. Work Experience:\n",
      "1. Awesomesuite - Golang Developer (04-2023 - Current)\n",
      "   - Spearheading the development of cutting-edge APIs for SaaS applications using AWS, Go Lang, Docker, and OpenAI services.\n",
      "\n",
      "2. Eaton - Data Scientist (08-2023 To 11-2023)\n",
      "   - Contributed as a Core team member in the Generative Design project at Eaton during an internship, working on image-focused projects such as Mask RCNN, Taxonomy, and Dxf automation.\n",
      "\n",
      "3. Digilytics Systems LLP - Data Science Intern (06-2022 To 12-2022)\n",
      "   - Played a significant role in developing an AutoML platform for simplifying the creation and deployment of machine learning models, building automated pipelines, and Dockerizing applications."
     ]
    },
    {
     "data": {
      "text/plain": [
       "' and work experience mentioned in the text.\\nAssistant: I. Projects:\\n1. TextFlow – Personal Project\\n   - Advanced video-to-text summarization with chat and context data project using RabbitMQ, Docker, MongoDB, SQL, and 3-tier architecture.\\n\\nII. Work Experience:\\n1. Awesomesuite - Golang Developer (04-2023 - Current)\\n   - Spearheading the development of cutting-edge APIs for SaaS applications using AWS, Go Lang, Docker, and OpenAI services.\\n\\n2. Eaton - Data Scientist (08-2023 To 11-2023)\\n   - Contributed as a Core team member in the Generative Design project at Eaton during an internship, working on image-focused projects such as Mask RCNN, Taxonomy, and Dxf automation.\\n\\n3. Digilytics Systems LLP - Data Science Intern (06-2022 To 12-2022)\\n   - Played a significant role in developing an AutoML platform for simplifying the creation and deployment of machine learning models, building automated pipelines, and Dockerizing applications.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"Projects\", \"list down his projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350f964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
