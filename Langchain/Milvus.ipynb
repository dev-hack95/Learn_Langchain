{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d36f5e93-e39d-48b5-bca3-c9aa64937e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_community.llms import CTransformers\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676a87f1-381d-492b-a512-f9f25d5f8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeAnalyser:\n",
    "    def __init__(self, resume) -> None:\n",
    "        \"\"\"\n",
    "        Info:\n",
    "          A Resume vector store function\n",
    "        Args:\n",
    "          resume[Document] --> A pdf document\n",
    "        Returns:\n",
    "          None\n",
    "        \"\"\"\n",
    "        self.resume = resume\n",
    "        self.pdf_loder = PyMuPDFLoader\n",
    "        self.callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "        self.embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.human_template = \"\"\"{question}\"\"\"\n",
    "        self.system_template = \"You are AI assiatant that can analyse the given text and answer the questions according based on given text be more specific about answer: {text}\"\n",
    "        self.collection_name = \"resume_collections\"\n",
    "        self.client_settings = {\n",
    "            \"host\": \"192.168.43.163\",\n",
    "            \"port\": \"19530\"}\n",
    "        self.config = {\n",
    "            'max_new_tokens': 512,\n",
    "            'repetition_penalty': 1.1,\n",
    "            'context_length': 2000,\n",
    "        }\n",
    "        self.model = CTransformers(\n",
    "            model='C:\\\\Users\\\\Saiprasad\\\\.cache\\\\huggingface\\\\hub\\\\models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF\\\\snapshots\\\\3a6fbf4a41a1d52e415a4958cde6856d34b2db93\\\\mistral-7b-instruct-v0.2.Q4_K_M.gguf',\n",
    "            model_type='llama', config=self.config, callback_manager=self.callback_manager)\n",
    "    def Analyse(self, param1, param2):\n",
    "        \"\"\"\n",
    "        Info:\n",
    "          This function used cosine simalarity to analyse the resume\n",
    "        Args:\n",
    "          resume --> Input Resume\n",
    "        Returns:\n",
    "          str --> Returns data based on Cosine-similarity\n",
    "        \"\"\"\n",
    "        resume_data = self.pdf_loder(self.resume)\n",
    "        resumes_data = resume_data.load()\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=10,\n",
    "            length_function=len,\n",
    "            is_separator_regex=False)\n",
    "        data = text_splitter.split_documents(resumes_data)\n",
    "        db = Milvus.from_documents(\n",
    "            data, \n",
    "            self.embedding_model, \n",
    "            connection_args=self.client_settings, \n",
    "            collection_name = self.collection_name)\n",
    "        docs = db.similarity_search(param1, k = 1)\n",
    "        human_prompt = HumanMessagePromptTemplate.from_template(self.human_template)\n",
    "        system_prompt = SystemMessagePromptTemplate.from_template(self.system_template)\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "        prompt = chat_prompt.format_prompt(question=param2, text=docs).to_messages()\n",
    "        return self.model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76263811-eb89-47fb-a8df-26e57853b5c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\LLM\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "analyser = ResumeAnalyser(\"../data/Saiprasad Toshatwad.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c01f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Assistant: Based on the provided text, the skills mentioned in the resume are:\n",
      "\n",
      "1. SQL (MySQL, PostgreSQL), VectorDB’s\n",
      "2. Python, LangChain (Pandas, Tensorflow, Yellowbrick, Shap, NumPy, Scikit-learn, API, ORM.. etc.)\n",
      "3. Golang, ORM\n",
      "4. MLOps: Linux, Kedro, Docker, Git, DVC, MLflow.\n",
      "\n",
      "These are the specific technology skills and tools mentioned in the text."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.\\nAssistant: Based on the provided text, the skills mentioned in the resume are:\\n\\n1. SQL (MySQL, PostgreSQL), VectorDB’s\\n2. Python, LangChain (Pandas, Tensorflow, Yellowbrick, Shap, NumPy, Scikit-learn, API, ORM.. etc.)\\n3. Golang, ORM\\n4. MLOps: Linux, Kedro, Docker, Git, DVC, MLflow.\\n\\nThese are the specific technology skills and tools mentioned in the text.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"skills\", \"list down his skill sections on resume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf2bec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " or experiences related to Python, Tensorflow, and SQL.\n",
      "Assistant: Based on the provided text, Saiprasad Toshatwad has mentioned proficiency in using Python with several libraries including Pandas, Tensorflow, Yellowbrick, Shap, NumPy, Scikit-learn, API, ORM, and SQL (MySQL, PostgreSQL), VectorDB. Therefore, his projects or experiences likely involve the application of these technologies. However, the text does not provide specific details about any particular projects or experiences he's had with these tools. It only states that he has the necessary skills in them."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" or experiences related to Python, Tensorflow, and SQL.\\nAssistant: Based on the provided text, Saiprasad Toshatwad has mentioned proficiency in using Python with several libraries including Pandas, Tensorflow, Yellowbrick, Shap, NumPy, Scikit-learn, API, ORM, and SQL (MySQL, PostgreSQL), VectorDB. Therefore, his projects or experiences likely involve the application of these technologies. However, the text does not provide specific details about any particular projects or experiences he's had with these tools. It only states that he has the necessary skills in them.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"Projects\", \"Tell me about his projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a350f964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " projects, with detailed reasoning please.\n",
      "\n",
      "Assistant: Based on the provided text, Saiprasad Toshatwad's experience at Eaton during his internship was quite impressive. He was a core team member in the Generative Design project, where he led various image-focused projects. The specific projects mentioned were Mask RCNN, Taxonomy, and Dxf automation. \n",
      "\n",
      "Mask RCNN is a popular object detection system based on Convolutional Neural Networks (CNNs) that uses a region proposal-based convolutional neural network architecture to perform both object detection and semantic segmentation at the pixel level. Leading this project indicates a strong understanding of image processing, machine learning, and possibly deep learning techniques.\n",
      "\n",
      "Taxonomy is a branch of science concerned with classification. In the context of data science, it could refer to creating or managing a taxonomy for data organization and analysis. This project shows his ability to organize and understand complex data structures, which is a crucial skill in data science.\n",
      "\n",
      "Dxf automation suggests that he worked on automating processes related to DXF (Drawing Exchange Format), which is a CAD data file format designed to enable data interoperability between applications and platforms. This project demonstrates his proficiency in programming, automation tools, and understanding of CAD systems.\n",
      "\n",
      "Based on this information, I would rate Saiprasad's work at Eaton an 8.5 out of 10 for a normal intern project. His role was more than just an intern as he led projects and demonstrated a deep dedication to innovation and effective problem-solving. However, it's important to note that a higher scoring scale might yield different results depending on the specific goals or expectations of the organization or the individual projects."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" projects, with detailed reasoning please.\\n\\nAssistant: Based on the provided text, Saiprasad Toshatwad's experience at Eaton during his internship was quite impressive. He was a core team member in the Generative Design project, where he led various image-focused projects. The specific projects mentioned were Mask RCNN, Taxonomy, and Dxf automation. \\n\\nMask RCNN is a popular object detection system based on Convolutional Neural Networks (CNNs) that uses a region proposal-based convolutional neural network architecture to perform both object detection and semantic segmentation at the pixel level. Leading this project indicates a strong understanding of image processing, machine learning, and possibly deep learning techniques.\\n\\nTaxonomy is a branch of science concerned with classification. In the context of data science, it could refer to creating or managing a taxonomy for data organization and analysis. This project shows his ability to organize and understand complex data structures, which is a crucial skill in data science.\\n\\nDxf automation suggests that he worked on automating processes related to DXF (Drawing Exchange Format), which is a CAD data file format designed to enable data interoperability between applications and platforms. This project demonstrates his proficiency in programming, automation tools, and understanding of CAD systems.\\n\\nBased on this information, I would rate Saiprasad's work at Eaton an 8.5 out of 10 for a normal intern project. His role was more than just an intern as he led projects and demonstrated a deep dedication to innovation and effective problem-solving. However, it's important to note that a higher scoring scale might yield different results depending on the specific goals or expectations of the organization or the individual projects.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"Eaton\", \"Tell me about his experiances in Eaton and and score his work on sclae of 10 w.r.t normal intern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6ffce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Assistant: Based on the provided text, the individual has been working as a Golang Developer at AwesomeSuite since April 2023. Their role includes spearheading the development of APIs for SaaS applications and leveraging AWS for seamless deployment across multiple development environments. They have led the charge in API creation and backend development. Given this information, it's reasonable to assume that they have a solid understanding of Golang, API development, and AWS, which goes beyond what you'd typically expect from an intern. Therefore, based on the text, I would rate their experience level above average, perhaps around 7 or 8 out of 10. However, without further context or additional information, this rating is an estimate."
     ]
    },
    {
     "data": {
      "text/plain": [
       "\".\\n\\nAssistant: Based on the provided text, the individual has been working as a Golang Developer at AwesomeSuite since April 2023. Their role includes spearheading the development of APIs for SaaS applications and leveraging AWS for seamless deployment across multiple development environments. They have led the charge in API creation and backend development. Given this information, it's reasonable to assume that they have a solid understanding of Golang, API development, and AWS, which goes beyond what you'd typically expect from an intern. Therefore, based on the text, I would rate their experience level above average, perhaps around 7 or 8 out of 10. However, without further context or additional information, this rating is an estimate.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.Analyse(\"AwesomeSuite\", \"Tell me about his experiances in Awesomesuite and score his work on sclae of 10 w.r.t normal intern\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039077b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
